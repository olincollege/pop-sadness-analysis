{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Has Pop Music Gotten Sadder over the Past 10 Years?**\n",
    "\n",
    "## Will Young and Rainier Hardjanto\n",
    "\n",
    "**Research Question**\n",
    "\n",
    " Americans are getting sadder. Ten years ago, a yearly Gallup poll ranked the US as the 11th happiest country. This year, they were ranked 23rd. Senator Chris Murphy recently spoke out on this, saying \"over the last 10 years the rate of happiness, of contentment, of fulfillment, self-reported by Americans, is dropping\". This brings up the interesting question of whether the music we listen to has gotten sadder with us. There is not a clear instinctual answer to this question: one could speculate that we turn to music to escape from our reality, which would mean that our music would get happier as we get sadder, but it is also plausible that we want to relate to music more than we want to use it to escape, which would lead to our music getting sadder with us. In order to investigate this question, we will be performing sentiment analysis on the lyrics of the most popular songs from 2013-2023.\n",
    "\n",
    "**Methodology**\n",
    "\n",
    "The data that we used to address our research question is the lyrics from every song on the year-end Billboard Hot 100 chart for every year from 2013 through 2023. This data was pulled from the Genius website (https://genius.com/), an online music encyclopedia that contains lyrics to millions of songs.\n",
    "\n",
    "To scrape this data, we first imported our libraries; Pandas was used to help organize our scraped data and the LyricsGenius library was used to simplify the process of making requests through Genius's API. We also imported our helper function file and our API key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "from lyricsgenius import Genius\n",
    "import helper_function\n",
    "import api_key  # You'll have to make one of these yourself on the Genius website\n",
    "\n",
    "genius = Genius(api_key.client_access_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then loaded and formatted our initial data. In this case, our initial data was a database of the title, artist, year, and chart position for every song we were planning to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and format billboard data\n",
    "billboard_df = pd.read_csv(\"billboard_100.csv\")\n",
    "artists = helper_function.generate(billboard_df)\n",
    "artists_series = pd.Series(artists)\n",
    "lyrics = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our data was loaded, we were ready to begin scraping songs. This process took quite a long time (multiple hours). Once the process was complete, the lyrics were added to our original data and the completed dataset was saved to a file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of songs to be scraped. If scraping all songs, should be 1100\n",
    "NUM_SONGS = 1100\n",
    "\n",
    "# Scrape the songs\n",
    "for i in range(NUM_SONGS):\n",
    "    while True:\n",
    "        try:\n",
    "            song = genius.search_song(\n",
    "                billboard_df[\"Title\"][i], artists_series[i]\n",
    "            )\n",
    "            break\n",
    "        except:  # If the request times out (which often happens), request again\n",
    "            pass\n",
    "    lyrics.append(helper_function.format_genius_lyrics(song.lyrics))\n",
    "\n",
    "# Save the scraped data into a DataFrame\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"No.\": billboard_df[\"No.\"][:NUM_SONGS],\n",
    "        \"Title\": billboard_df[\"Title\"][:NUM_SONGS],\n",
    "        \"Artists\": artists_series[:NUM_SONGS],\n",
    "        \"Year\": billboard_df[\"Year\"][:NUM_SONGS],\n",
    "        \"Lyrics\": pd.Series(lyrics),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Save the data to a file\n",
    "df.to_csv(\"billboard_data_with_lyrics\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use this data to answer the research question, we need to understand the emotions present in the lyrics. Determining these emotions will allow us to examine the trends of said emotions over time, from which we can see whether there are trends toward sadder lyrics. In order to determine these emotions, we processed the lyrics we scraped using NLTK's VADER. VADER, which stands for \"Valence Aware Dictionary and sEntiment Reasoner\" is a lexicon and rule-based sentiment analysis tool that rates the sentiment of a passage of text from -1 to 1, where -1 is extremely negative sentiment and 1 is extremely positive sentiment. We specifically selected VADER as our sentiment analysis tool because in addition to being the highest rated rule-based sentiment analysis tool, it is especially good at understanding slang, which is extremely common in pop music.\n",
    "\n",
    "The primary way that we processed this data was by finding the sentiment score for every song we scraped. We then added this data to the dataframe that we previously saved to the file, and used this dataframe to build our first visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/wyoung/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "import mplcursors  # separate package must be installed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib.patheffects import withSimplePatchShadow\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download(\"vader_lexicon\")  # Run this line the first time you run this code\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Import data\n",
    "loaded_data = pd.read_csv(\"billboard_data_with_lyrics\")\n",
    "lyrics_data = loaded_data[\"Lyrics\"]\n",
    "\n",
    "# FIRST VISUALIZATION - Polarity of Every Top Song with Trendline\n",
    "positivity_scores = []\n",
    "\n",
    "# Add a Positivity series to the Billboard dataframe\n",
    "for i in range(len(lyrics_data)):\n",
    "    positivity_scores.append(\n",
    "        analyzer.polarity_scores(lyrics_data[i])[\"compound\"]\n",
    "    )\n",
    "\n",
    "all_data = pd.concat(\n",
    "    [loaded_data, pd.DataFrame({\"Positivity\": positivity_scores})], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second way we processed our data was by finding the top 5 artists for every year based on a ranking algorithm we created. This algorithm gave a relative weight to each position on the chart, and summed the weights of each artist's songs to determine the top artists. We then took those artists and found the average polarity of all their Top 100 songs from that year, which we used to create our second visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_artist_polarityscore = []\n",
    "\n",
    "with open(\"billboard_data_with_lyrics.csv\", mode=\"r\", encoding=\"utf-8\") as file:\n",
    "    # Create a CSV reader\n",
    "    csv_reader = csv.reader(file)\n",
    "\n",
    "    # Convert it to a list to get the ability to use len() and indexing\n",
    "    rows = list(csv_reader)\n",
    "\n",
    "    # Iterate using indices\n",
    "    for j in range(11):\n",
    "        scores_by_artist = {}\n",
    "        for i in range(100):\n",
    "            score = 101 - i  # Calculate the score based on ranking\n",
    "            artist = rows[j * 100 + i][2]\n",
    "            if artist in scores_by_artist:\n",
    "                scores_by_artist[artist] += score\n",
    "            else:\n",
    "                scores_by_artist[artist] = score\n",
    "        # Step 2 & 3: Sort Artists by Total Score\n",
    "        sorted_artists = sorted(\n",
    "            scores_by_artist.items(), key=lambda x: x[1], reverse=True\n",
    "        )\n",
    "\n",
    "        # Step 4: Select the Top 5 Artists\n",
    "        top_5_artists = sorted_artists[:5]\n",
    "        top_5_artist_names = [artist[0] for artist in top_5_artists]\n",
    "\n",
    "        polarity_score = {}\n",
    "        polarity_count = {}\n",
    "        for i in range(100):\n",
    "            artist = rows[j * 100 + i][2]\n",
    "\n",
    "            if (artist in top_5_artist_names) is False:\n",
    "                continue\n",
    "\n",
    "            if artist in polarity_score:\n",
    "                polarity_score[artist] += helper_function.polarity(\n",
    "                    rows[j * 100 + i][4]\n",
    "                )[\"compound\"]\n",
    "                polarity_count[artist] += 1\n",
    "            else:\n",
    "                polarity_score[artist] = helper_function.polarity(\n",
    "                    rows[j * 100 + i][4]\n",
    "                )[\"compound\"]\n",
    "                polarity_count[artist] = 1\n",
    "\n",
    "        for x, y in polarity_score.items():\n",
    "            polarity_score[x] /= polarity_count[x]\n",
    "        top_artist_polarityscore.append(polarity_score)\n",
    "\n",
    "extended_data = top_artist_polarityscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third way we processed our data was by creating dictionaries of all the negative words (based on their VADER sentiment score) and the amount of times they appear in the lyrics as a whole. We created three dictionaries - one from 2013 to 2016, one from 2017 to 2020, and one from 2021 to 2023 - to investigate how the languaged used to describe sadness and negativity changed over time, and used these to create our third visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'irrelevant_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words:\n\u001b[1;32m     18\u001b[0m     word \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     19\u001b[0m         word\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     20\u001b[0m     )  \u001b[38;5;66;03m# Ensure upper/lower case does not affect visual\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m irrelevant_words:\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m helper_function\u001b[38;5;241m.\u001b[39mpolarity(word)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompound\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.3\u001b[39m:\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;66;03m# Choose the correct dictionary based on the count\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'irrelevant_words' is not defined"
     ]
    }
   ],
   "source": [
    "CSV_FILE_PATH = \"billboard_data_with_lyrics.csv\"\n",
    "\n",
    "# List of words that are not very interesting, don't have interesting changes,\n",
    "# and reduce the effectiveness of the word cloud visual\n",
    "irrelevant_words = [\n",
    "    \"fuck\",\n",
    "    \"bitch\",\n",
    "    \"bitches\",\n",
    "    \"dick\",\n",
    "    \"niggas\",\n",
    "    \"shit\",\n",
    "    \"fucked\",\n",
    "    \"bad\",\n",
    "    \"damn\",\n",
    "    \"ass\",\n",
    "]\n",
    "\n",
    "with open(CSV_FILE_PATH, encoding=\"utf8\", newline=\"\") as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "\n",
    "    words_dictionary = {}\n",
    "    words_dictionary1 = {}\n",
    "    words_dictionary2 = {}\n",
    "    list_of_dictionary = [\n",
    "        words_dictionary,\n",
    "        words_dictionary1,\n",
    "        words_dictionary2,\n",
    "    ]\n",
    "\n",
    "    for count, row in enumerate(csvreader, start=0):\n",
    "        words = helper_function.split_text_into_words(row[4])\n",
    "        for word in words:\n",
    "            word = (\n",
    "                word.lower()\n",
    "            )  # Ensure upper/lower case does not affect visual\n",
    "            if word in irrelevant_words:\n",
    "                continue\n",
    "            if helper_function.polarity(word)[\"compound\"] < -0.3:\n",
    "                # Choose the correct dictionary based on the count\n",
    "                current_dict = list_of_dictionary[count // 400]\n",
    "                # Use get to avoid KeyError, defaults to 0 if the key doesn't\n",
    "                # exist\n",
    "                current_dict[word] = current_dict.get(word, 0) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'positivity_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# FIRST VISUALIZATION - Polarity of Every Top Song with Trendline\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Plot average positivity scores for each year from the past 10 years\u001b[39;00m\n\u001b[1;32m      4\u001b[0m scores \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28msum\u001b[39m(positivity_scores[:\u001b[38;5;241m101\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28msum\u001b[39m(positivity_scores[\u001b[38;5;241m100\u001b[39m:\u001b[38;5;241m201\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28msum\u001b[39m(positivity_scores[\u001b[38;5;241m200\u001b[39m:\u001b[38;5;241m301\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28msum\u001b[39m(positivity_scores[\u001b[38;5;241m300\u001b[39m:\u001b[38;5;241m401\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28msum\u001b[39m(positivity_scores[\u001b[38;5;241m400\u001b[39m:\u001b[38;5;241m501\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28msum\u001b[39m(positivity_scores[\u001b[38;5;241m500\u001b[39m:\u001b[38;5;241m601\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28msum\u001b[39m(positivity_scores[\u001b[38;5;241m600\u001b[39m:\u001b[38;5;241m701\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28msum\u001b[39m(positivity_scores[\u001b[38;5;241m700\u001b[39m:\u001b[38;5;241m801\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28msum\u001b[39m(positivity_scores[\u001b[38;5;241m800\u001b[39m:\u001b[38;5;241m901\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28msum\u001b[39m(positivity_scores[\u001b[38;5;241m900\u001b[39m:\u001b[38;5;241m1001\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28msum\u001b[39m(positivity_scores[\u001b[38;5;241m1000\u001b[39m:\u001b[38;5;241m1101\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     16\u001b[0m ]\n\u001b[1;32m     17\u001b[0m years \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;241m2013.5\u001b[39m,\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;241m2014.5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;241m2023.5\u001b[39m,\n\u001b[1;32m     29\u001b[0m ]  \u001b[38;5;66;03m# add .5 to all years to make visualization more effective\u001b[39;00m\n\u001b[1;32m     31\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'positivity_scores' is not defined"
     ]
    }
   ],
   "source": [
    "# FIRST VISUALIZATION - Polarity of Every Top Song with Trendline\n",
    "\n",
    "# Plot average positivity scores for each year from the past 10 years\n",
    "scores = [\n",
    "    sum(positivity_scores[:101]) / 100,\n",
    "    sum(positivity_scores[100:201]) / 100,\n",
    "    sum(positivity_scores[200:301]) / 100,\n",
    "    sum(positivity_scores[300:401]) / 100,\n",
    "    sum(positivity_scores[400:501]) / 100,\n",
    "    sum(positivity_scores[500:601]) / 100,\n",
    "    sum(positivity_scores[600:701]) / 100,\n",
    "    sum(positivity_scores[700:801]) / 100,\n",
    "    sum(positivity_scores[800:901]) / 100,\n",
    "    sum(positivity_scores[900:1001]) / 100,\n",
    "    sum(positivity_scores[1000:1101]) / 100,\n",
    "]\n",
    "years = [\n",
    "    2013.5,\n",
    "    2014.5,\n",
    "    2015.5,\n",
    "    2016.5,\n",
    "    2017.5,\n",
    "    2018.5,\n",
    "    2019.5,\n",
    "    2020.5,\n",
    "    2021.5,\n",
    "    2022.5,\n",
    "    2023.5,\n",
    "]  # add .5 to all years to make visualization more effective\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(years, scores, \"r--\")  # plot general trend line\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Polarity Score\")\n",
    "plt.title(\"Polarity Score of Every Top 100 Song, 2013-2023\")\n",
    "# Plot every song and its score\n",
    "indiv_scores = plt.scatter(\n",
    "    np.linspace(2013, 2023.99, num=1100), positivity_scores\n",
    ")\n",
    "\n",
    "\n",
    "# Using the mplcursors library, display information about each data point\n",
    "# when you hover over it.\n",
    "def show_hover_panel(get_text_func=None):\n",
    "    \"\"\"\n",
    "    Displays specified content whenever the cursor is hovering over a data\n",
    "    point.\n",
    "\n",
    "    Args:\n",
    "        get_text_func: A string that contains text to be displayed. If it is\n",
    "        None, no box will be displayed.\n",
    "\n",
    "    Returns:\n",
    "        a cursor object that displays a box contanining specified content\n",
    "        whenever it hovers over a data point.\n",
    "    \"\"\"\n",
    "    cursor = mplcursors.cursor(\n",
    "        hover=2,  # Transient\n",
    "        annotation_kwargs=dict(\n",
    "            bbox=dict(\n",
    "                boxstyle=\"square,pad=0.5\",\n",
    "                facecolor=\"white\",\n",
    "                edgecolor=\"#ddd\",\n",
    "                linewidth=0.5,\n",
    "                path_effects=[withSimplePatchShadow(offset=(1.5, -1.5))],\n",
    "            ),\n",
    "            linespacing=1.5,\n",
    "            arrowprops=None,\n",
    "        ),\n",
    "        highlight=True,\n",
    "        highlight_kwargs={\"linewidth\": 2},\n",
    "    )\n",
    "\n",
    "    if get_text_func:\n",
    "        cursor.connect(\n",
    "            event=\"add\",\n",
    "            func=lambda sel: sel.annotation.set_text(get_text_func(sel.index)),\n",
    "        )\n",
    "    return cursor\n",
    "\n",
    "\n",
    "def on_add(index):\n",
    "    \"\"\"\n",
    "    Returns the text that should be displayed when the cursor is hovering over a\n",
    "    specific data point.\n",
    "    Args:\n",
    "        index: an integer representing the index of the current data point in\n",
    "        the dataset\n",
    "        dataframe: the dataframe for the data being displayed.\n",
    "    Returns:\n",
    "        A string containing the text to be displayed when the specific data\n",
    "        point is hovered over.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parts = [\n",
    "            f\"Song: {all_data['Title'][index]}\",\n",
    "            f\"Artist: {all_data['Artists'][index]}\",\n",
    "            f\"Chart Position: {all_data['No.'][index]}\",\n",
    "            f\"Score: {all_data['Positivity'][index]}\",\n",
    "        ]\n",
    "        return \"\\n\".join(parts)\n",
    "    except KeyError:  # don't hover when the cursor is over the trendline\n",
    "        return None\n",
    "\n",
    "\n",
    "show_hover_panel(on_add)  # add hover labels\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
